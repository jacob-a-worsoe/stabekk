{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing notebook, remove bad points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Get the absolute path of parent folder\n",
    "current_dir = os.path.abspath(\"\")\n",
    "parent_dir = os.path.join(current_dir, os.pardir)\n",
    "\n",
    "# Add to sys.path\n",
    "sys.path.append(parent_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ml_combat as ml\n",
    "from ml_combat import data\n",
    "from ml_combat.MetaModel import MetaModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from prophet import Prophet\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogluon.tabular import TabularDataset, TabularPredictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class AutoGluonJacob(MetaModel):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__(\"AutoGluon Jacob\")\n",
    "\n",
    "        # autogluon features\n",
    "        # TabularPredictor (usage : **params_TabularPredictor)\n",
    "        self.params_TabularPredictor = \\\n",
    "            {\n",
    "                'label': 'y',\n",
    "                'problem_type': 'regression', \n",
    "                'eval_metric': 'mean_absolute_error',\n",
    "                'verbosity': 0,\n",
    "            } \n",
    "        # TabularPredictor.fit\n",
    "        self.params_TabularPredictor_fit = \\\n",
    "            {\n",
    "                'time_limit': 60*2.5,\n",
    "                'presets': 'high_quality', # [‘best_quality’, ‘high_quality’, ‘good_quality’, ‘medium_quality’, ‘optimize_for_deployment’, ‘interpretable’, ‘ignore_text’]\n",
    "                'hyperparameters': 'default',\n",
    "                # 'auto_stack': False,\n",
    "                # 'num_bag_folds': None, # set automatically by auto_stack True\n",
    "                # 'num_bag_sets': None, # set to 20 because of auto_stack\n",
    "                # 'num_stack_levels': None, # set automatically by auto_stack True\n",
    "                'hyperparameter_tune_kwargs': 'auto', # None to disable\n",
    "                # 'refit_full': True,\n",
    "                # 'feature_prune_kwargs': {}, # If None, do not perform feature pruning. If empty dictionary, perform feature pruning with default configurations.\n",
    "            }\n",
    "\n",
    "        self.use_tuning_data = True # 'sample_weight', 'random'\n",
    "        self.use_sample_weight = True\n",
    "\n",
    "        if self.use_sample_weight: # auto_weight a feature that exists\n",
    "            self.params_TabularPredictor['sample_weight'] = 'sample_importance'\n",
    "        \n",
    "\n",
    "    def preprocess(self, df: pd.DataFrame):\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        temp_df = df.copy()\n",
    "\n",
    "        temp_df['total_rad_1h:J'] = temp_df['diffuse_rad_1h:J'] + temp_df['direct_rad_1h:J']    \n",
    "        \n",
    "        # Extracting hour-of-day and month, and making them cyclical\n",
    "        temp_df['hour'] = temp_df['ds'].dt.hour\n",
    "        temp_df['hour'] = (np.sin(2 * np.pi * (temp_df['hour'] - 4)/ 24) + 1) / 2\n",
    "\n",
    "        temp_df['dayofyear'] = temp_df['ds'].dt.day_of_year\n",
    "        temp_df['dayofyear'] = np.sin(2 * np.pi * (temp_df['dayofyear'] - 80)/ 365)\n",
    "\n",
    "        # temp_df['year'] = temp_df['ds'].dt.hour\n",
    "        temp_df['month'] = temp_df['ds'].dt.month\n",
    "        # temp_df['day'] = temp_df['ds'].dt.day\n",
    "        # temp_df['dayofweek'] = temp_df['ds'].dt.dayofweek\n",
    "\n",
    "        if self.use_sample_weight:\n",
    "            # Emphasize test start-end: Starting date: 2023-05-01 00:00:00 Ending data 2023-07-03 23:00:00\n",
    "            temp_df['sample_importance'] = 1\n",
    "            temp_df.loc[(temp_df['ds'].dt.month >= 5) & \n",
    "                        (temp_df['ds'].dt.month < 7), 'sample_importance'] = 2\n",
    "            \n",
    "            # temp_df.loc[(temp_df['ds'].dt.month == 7) &\n",
    "            #             (temp_df['ds'].dt.day <= 4), 'sample_importance'] = 2\n",
    "\n",
    "\n",
    "\n",
    "        return temp_df.drop(columns=['ds'])\n",
    "\n",
    "    def train(self, df):\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        temp_df = self.preprocess(df)\n",
    "\n",
    "        if self.use_tuning_data:\n",
    "\n",
    "            tuning_data = temp_df[(temp_df['month'] == 5) | (temp_df['month'] == 6)].sample(frac=0.5, random_state=42)\n",
    "            train_data = TabularDataset(temp_df[~temp_df.isin(tuning_data.to_dict(orient='list')).all(1)])\n",
    "\n",
    "            self.model = TabularPredictor(**self.params_TabularPredictor).fit(train_data, tuning_data=tuning_data, use_bag_holdout=True, **self.params_TabularPredictor_fit)\n",
    "        else:\n",
    "            train_data = TabularDataset(temp_df)\n",
    "\n",
    "            self.model = TabularPredictor(**self.params_TabularPredictor).fit(train_data, **self.params_TabularPredictor_fit)\n",
    "\n",
    "    def predict(self, df):\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        df = self.preprocess(df)\n",
    "\n",
    "        features = [col for col in df.columns if col != 'y']\n",
    "        X = df[features]\n",
    "\n",
    "\n",
    "\n",
    "        y_preds = self.model.predict(X)\n",
    "        print(\"AUTOGLUON MODEL OVERVIEW:\")\n",
    "        print(self.model.get_model_names())\n",
    "       \n",
    "\n",
    "        out_df = pd.DataFrame(data={'y_pred': y_preds})\n",
    "\n",
    "        return out_df\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###########################################\n",
      "###############  LOCATION A ###############\n",
      "###########################################\n",
      "Testing AutoGluon Jacob\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/jacobworsoe/Documents/H23/Maskinlæring/stabekk/notebooks/autogluon_valid.ipynb Cell 8\u001b[0m line \u001b[0;36m1\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/jacobworsoe/Documents/H23/Maskinl%C3%A6ring/stabekk/notebooks/autogluon_valid.ipynb#X16sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m df_location \u001b[39m=\u001b[39m df[df[\u001b[39m'\u001b[39m\u001b[39mlocation\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m==\u001b[39m location]\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/jacobworsoe/Documents/H23/Maskinl%C3%A6ring/stabekk/notebooks/autogluon_valid.ipynb#X16sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m agh \u001b[39m=\u001b[39m AutoGluonJacob()\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/jacobworsoe/Documents/H23/Maskinl%C3%A6ring/stabekk/notebooks/autogluon_valid.ipynb#X16sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m agh\u001b[39m.\u001b[39;49mtest(df_location, n_splits\u001b[39m=\u001b[39;49m\u001b[39m2\u001b[39;49m)\n",
      "File \u001b[0;32m~/Documents/H23/Maskinlæring/stabekk/notebooks/../ml_combat/MetaModel.py:41\u001b[0m, in \u001b[0;36mMetaModel.test\u001b[0;34m(self, df, n_splits)\u001b[0m\n\u001b[1;32m     38\u001b[0m train_partition \u001b[39m=\u001b[39m df\u001b[39m.\u001b[39miloc[train_index]\n\u001b[1;32m     39\u001b[0m valid_partition \u001b[39m=\u001b[39m df\u001b[39m.\u001b[39miloc[test_index]\n\u001b[0;32m---> 41\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain(train_partition)\n\u001b[1;32m     42\u001b[0m predictions \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpredict(valid_partition)\n\u001b[1;32m     44\u001b[0m y_true \u001b[39m=\u001b[39m valid_partition[\u001b[39m'\u001b[39m\u001b[39my\u001b[39m\u001b[39m'\u001b[39m]\n",
      "\u001b[1;32m/Users/jacobworsoe/Documents/H23/Maskinlæring/stabekk/notebooks/autogluon_valid.ipynb Cell 8\u001b[0m line \u001b[0;36m7\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jacobworsoe/Documents/H23/Maskinl%C3%A6ring/stabekk/notebooks/autogluon_valid.ipynb#X16sZmlsZQ%3D%3D?line=75'>76</a>\u001b[0m     tuning_data \u001b[39m=\u001b[39m temp_df[(temp_df[\u001b[39m'\u001b[39m\u001b[39mmonth\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m==\u001b[39m \u001b[39m5\u001b[39m) \u001b[39m|\u001b[39m (temp_df[\u001b[39m'\u001b[39m\u001b[39mmonth\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m==\u001b[39m \u001b[39m6\u001b[39m)]\u001b[39m.\u001b[39msample(frac\u001b[39m=\u001b[39m\u001b[39m0.05\u001b[39m, random_state\u001b[39m=\u001b[39m\u001b[39m142\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jacobworsoe/Documents/H23/Maskinl%C3%A6ring/stabekk/notebooks/autogluon_valid.ipynb#X16sZmlsZQ%3D%3D?line=76'>77</a>\u001b[0m     train_data \u001b[39m=\u001b[39m TabularDataset(temp_df[\u001b[39m~\u001b[39mtemp_df\u001b[39m.\u001b[39misin(tuning_data\u001b[39m.\u001b[39mto_dict(orient\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mlist\u001b[39m\u001b[39m'\u001b[39m))\u001b[39m.\u001b[39mall(\u001b[39m1\u001b[39m)])\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/jacobworsoe/Documents/H23/Maskinl%C3%A6ring/stabekk/notebooks/autogluon_valid.ipynb#X16sZmlsZQ%3D%3D?line=78'>79</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel \u001b[39m=\u001b[39m TabularPredictor(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mparams_TabularPredictor)\u001b[39m.\u001b[39;49mfit(train_data, tuning_data\u001b[39m=\u001b[39;49mtuning_data, use_bag_holdout\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mparams_TabularPredictor_fit)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jacobworsoe/Documents/H23/Maskinl%C3%A6ring/stabekk/notebooks/autogluon_valid.ipynb#X16sZmlsZQ%3D%3D?line=79'>80</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jacobworsoe/Documents/H23/Maskinl%C3%A6ring/stabekk/notebooks/autogluon_valid.ipynb#X16sZmlsZQ%3D%3D?line=80'>81</a>\u001b[0m     train_data \u001b[39m=\u001b[39m TabularDataset(temp_df)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/autogluon/core/utils/decorators.py:31\u001b[0m, in \u001b[0;36munpack.<locals>._unpack_inner.<locals>._call\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(f)\n\u001b[1;32m     29\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_call\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m     30\u001b[0m     gargs, gkwargs \u001b[39m=\u001b[39m g(\u001b[39m*\u001b[39mother_args, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m---> 31\u001b[0m     \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39;49mgargs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mgkwargs)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/autogluon/tabular/predictor/predictor.py:986\u001b[0m, in \u001b[0;36mTabularPredictor.fit\u001b[0;34m(self, train_data, tuning_data, time_limit, presets, hyperparameters, feature_metadata, infer_limit, infer_limit_batch_size, fit_weighted_ensemble, calibrate_decision_threshold, num_cpus, num_gpus, **kwargs)\u001b[0m\n\u001b[1;32m    984\u001b[0m     aux_kwargs[\u001b[39m\"\u001b[39m\u001b[39mfit_weighted_ensemble\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m    985\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msave(silent\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)  \u001b[39m# Save predictor to disk to enable prediction and training after interrupt\u001b[39;00m\n\u001b[0;32m--> 986\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_learner\u001b[39m.\u001b[39;49mfit(\n\u001b[1;32m    987\u001b[0m     X\u001b[39m=\u001b[39;49mtrain_data,\n\u001b[1;32m    988\u001b[0m     X_val\u001b[39m=\u001b[39;49mtuning_data,\n\u001b[1;32m    989\u001b[0m     X_unlabeled\u001b[39m=\u001b[39;49munlabeled_data,\n\u001b[1;32m    990\u001b[0m     holdout_frac\u001b[39m=\u001b[39;49mholdout_frac,\n\u001b[1;32m    991\u001b[0m     num_bag_folds\u001b[39m=\u001b[39;49mnum_bag_folds,\n\u001b[1;32m    992\u001b[0m     num_bag_sets\u001b[39m=\u001b[39;49mnum_bag_sets,\n\u001b[1;32m    993\u001b[0m     num_stack_levels\u001b[39m=\u001b[39;49mnum_stack_levels,\n\u001b[1;32m    994\u001b[0m     hyperparameters\u001b[39m=\u001b[39;49mhyperparameters,\n\u001b[1;32m    995\u001b[0m     core_kwargs\u001b[39m=\u001b[39;49mcore_kwargs,\n\u001b[1;32m    996\u001b[0m     aux_kwargs\u001b[39m=\u001b[39;49maux_kwargs,\n\u001b[1;32m    997\u001b[0m     time_limit\u001b[39m=\u001b[39;49mtime_limit,\n\u001b[1;32m    998\u001b[0m     infer_limit\u001b[39m=\u001b[39;49minfer_limit,\n\u001b[1;32m    999\u001b[0m     infer_limit_batch_size\u001b[39m=\u001b[39;49minfer_limit_batch_size,\n\u001b[1;32m   1000\u001b[0m     verbosity\u001b[39m=\u001b[39;49mverbosity,\n\u001b[1;32m   1001\u001b[0m     use_bag_holdout\u001b[39m=\u001b[39;49muse_bag_holdout,\n\u001b[1;32m   1002\u001b[0m )\n\u001b[1;32m   1003\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_set_post_fit_vars()\n\u001b[1;32m   1005\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_post_fit(\n\u001b[1;32m   1006\u001b[0m     keep_only_best\u001b[39m=\u001b[39mkwargs[\u001b[39m\"\u001b[39m\u001b[39mkeep_only_best\u001b[39m\u001b[39m\"\u001b[39m],\n\u001b[1;32m   1007\u001b[0m     refit_full\u001b[39m=\u001b[39mkwargs[\u001b[39m\"\u001b[39m\u001b[39mrefit_full\u001b[39m\u001b[39m\"\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1012\u001b[0m     infer_limit\u001b[39m=\u001b[39minfer_limit,\n\u001b[1;32m   1013\u001b[0m )\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/autogluon/tabular/learner/abstract_learner.py:159\u001b[0m, in \u001b[0;36mAbstractTabularLearner.fit\u001b[0;34m(self, X, X_val, **kwargs)\u001b[0m\n\u001b[1;32m    157\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mAssertionError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mLearner is already fit.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    158\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_fit_input(X\u001b[39m=\u001b[39mX, X_val\u001b[39m=\u001b[39mX_val, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m--> 159\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fit(X\u001b[39m=\u001b[39;49mX, X_val\u001b[39m=\u001b[39;49mX_val, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/autogluon/tabular/learner/default_learner.py:157\u001b[0m, in \u001b[0;36mDefaultLearner._fit\u001b[0;34m(self, X, X_val, X_unlabeled, holdout_frac, num_bag_folds, num_bag_sets, time_limit, infer_limit, infer_limit_batch_size, verbosity, **trainer_fit_kwargs)\u001b[0m\n\u001b[1;32m    154\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39meval_metric \u001b[39m=\u001b[39m trainer\u001b[39m.\u001b[39meval_metric\n\u001b[1;32m    156\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msave()\n\u001b[0;32m--> 157\u001b[0m trainer\u001b[39m.\u001b[39;49mfit(\n\u001b[1;32m    158\u001b[0m     X\u001b[39m=\u001b[39;49mX,\n\u001b[1;32m    159\u001b[0m     y\u001b[39m=\u001b[39;49my,\n\u001b[1;32m    160\u001b[0m     X_val\u001b[39m=\u001b[39;49mX_val,\n\u001b[1;32m    161\u001b[0m     y_val\u001b[39m=\u001b[39;49my_val,\n\u001b[1;32m    162\u001b[0m     X_unlabeled\u001b[39m=\u001b[39;49mX_unlabeled,\n\u001b[1;32m    163\u001b[0m     holdout_frac\u001b[39m=\u001b[39;49mholdout_frac,\n\u001b[1;32m    164\u001b[0m     time_limit\u001b[39m=\u001b[39;49mtime_limit_trainer,\n\u001b[1;32m    165\u001b[0m     infer_limit\u001b[39m=\u001b[39;49minfer_limit,\n\u001b[1;32m    166\u001b[0m     infer_limit_batch_size\u001b[39m=\u001b[39;49minfer_limit_batch_size,\n\u001b[1;32m    167\u001b[0m     groups\u001b[39m=\u001b[39;49mgroups,\n\u001b[1;32m    168\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mtrainer_fit_kwargs,\n\u001b[1;32m    169\u001b[0m )\n\u001b[1;32m    170\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msave_trainer(trainer\u001b[39m=\u001b[39mtrainer)\n\u001b[1;32m    171\u001b[0m time_end \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/autogluon/tabular/trainer/auto_trainer.py:114\u001b[0m, in \u001b[0;36mAutoTrainer.fit\u001b[0;34m(self, X, y, hyperparameters, X_val, y_val, X_unlabeled, holdout_frac, num_stack_levels, core_kwargs, aux_kwargs, time_limit, infer_limit, infer_limit_batch_size, use_bag_holdout, groups, **kwargs)\u001b[0m\n\u001b[1;32m    111\u001b[0m log_str \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m}\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    112\u001b[0m logger\u001b[39m.\u001b[39mlog(\u001b[39m20\u001b[39m, log_str)\n\u001b[0;32m--> 114\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_train_multi_and_ensemble(\n\u001b[1;32m    115\u001b[0m     X\u001b[39m=\u001b[39;49mX,\n\u001b[1;32m    116\u001b[0m     y\u001b[39m=\u001b[39;49my,\n\u001b[1;32m    117\u001b[0m     X_val\u001b[39m=\u001b[39;49mX_val,\n\u001b[1;32m    118\u001b[0m     y_val\u001b[39m=\u001b[39;49my_val,\n\u001b[1;32m    119\u001b[0m     X_unlabeled\u001b[39m=\u001b[39;49mX_unlabeled,\n\u001b[1;32m    120\u001b[0m     hyperparameters\u001b[39m=\u001b[39;49mhyperparameters,\n\u001b[1;32m    121\u001b[0m     num_stack_levels\u001b[39m=\u001b[39;49mnum_stack_levels,\n\u001b[1;32m    122\u001b[0m     time_limit\u001b[39m=\u001b[39;49mtime_limit,\n\u001b[1;32m    123\u001b[0m     core_kwargs\u001b[39m=\u001b[39;49mcore_kwargs,\n\u001b[1;32m    124\u001b[0m     aux_kwargs\u001b[39m=\u001b[39;49maux_kwargs,\n\u001b[1;32m    125\u001b[0m     infer_limit\u001b[39m=\u001b[39;49minfer_limit,\n\u001b[1;32m    126\u001b[0m     infer_limit_batch_size\u001b[39m=\u001b[39;49minfer_limit_batch_size,\n\u001b[1;32m    127\u001b[0m     groups\u001b[39m=\u001b[39;49mgroups,\n\u001b[1;32m    128\u001b[0m )\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/autogluon/core/trainer/abstract_trainer.py:2371\u001b[0m, in \u001b[0;36mAbstractTrainer._train_multi_and_ensemble\u001b[0;34m(self, X, y, X_val, y_val, hyperparameters, X_unlabeled, num_stack_levels, time_limit, groups, **kwargs)\u001b[0m\n\u001b[1;32m   2369\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_rows_val \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(X_val)\n\u001b[1;32m   2370\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_cols_train \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mlist\u001b[39m(X\u001b[39m.\u001b[39mcolumns))\n\u001b[0;32m-> 2371\u001b[0m model_names_fit \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_multi_levels(\n\u001b[1;32m   2372\u001b[0m     X,\n\u001b[1;32m   2373\u001b[0m     y,\n\u001b[1;32m   2374\u001b[0m     hyperparameters\u001b[39m=\u001b[39;49mhyperparameters,\n\u001b[1;32m   2375\u001b[0m     X_val\u001b[39m=\u001b[39;49mX_val,\n\u001b[1;32m   2376\u001b[0m     y_val\u001b[39m=\u001b[39;49my_val,\n\u001b[1;32m   2377\u001b[0m     X_unlabeled\u001b[39m=\u001b[39;49mX_unlabeled,\n\u001b[1;32m   2378\u001b[0m     level_start\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m,\n\u001b[1;32m   2379\u001b[0m     level_end\u001b[39m=\u001b[39;49mnum_stack_levels \u001b[39m+\u001b[39;49m \u001b[39m1\u001b[39;49m,\n\u001b[1;32m   2380\u001b[0m     time_limit\u001b[39m=\u001b[39;49mtime_limit,\n\u001b[1;32m   2381\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[1;32m   2382\u001b[0m )\n\u001b[1;32m   2383\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_model_names()) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m   2384\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mAutoGluon did not successfully train any models\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/autogluon/core/trainer/abstract_trainer.py:395\u001b[0m, in \u001b[0;36mAbstractTrainer.train_multi_levels\u001b[0;34m(self, X, y, hyperparameters, X_val, y_val, X_unlabeled, base_model_names, core_kwargs, aux_kwargs, level_start, level_end, time_limit, name_suffix, relative_stack, level_time_modifier, infer_limit, infer_limit_batch_size)\u001b[0m\n\u001b[1;32m    393\u001b[0m         core_kwargs_level[\u001b[39m\"\u001b[39m\u001b[39mtime_limit\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m core_kwargs_level\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mtime_limit\u001b[39m\u001b[39m\"\u001b[39m, time_limit_core)\n\u001b[1;32m    394\u001b[0m         aux_kwargs_level[\u001b[39m\"\u001b[39m\u001b[39mtime_limit\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m aux_kwargs_level\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mtime_limit\u001b[39m\u001b[39m\"\u001b[39m, time_limit_aux)\n\u001b[0;32m--> 395\u001b[0m     base_model_names, aux_models \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstack_new_level(\n\u001b[1;32m    396\u001b[0m         X\u001b[39m=\u001b[39;49mX,\n\u001b[1;32m    397\u001b[0m         y\u001b[39m=\u001b[39;49my,\n\u001b[1;32m    398\u001b[0m         X_val\u001b[39m=\u001b[39;49mX_val,\n\u001b[1;32m    399\u001b[0m         y_val\u001b[39m=\u001b[39;49my_val,\n\u001b[1;32m    400\u001b[0m         X_unlabeled\u001b[39m=\u001b[39;49mX_unlabeled,\n\u001b[1;32m    401\u001b[0m         models\u001b[39m=\u001b[39;49mhyperparameters,\n\u001b[1;32m    402\u001b[0m         level\u001b[39m=\u001b[39;49mlevel,\n\u001b[1;32m    403\u001b[0m         base_model_names\u001b[39m=\u001b[39;49mbase_model_names,\n\u001b[1;32m    404\u001b[0m         core_kwargs\u001b[39m=\u001b[39;49mcore_kwargs_level,\n\u001b[1;32m    405\u001b[0m         aux_kwargs\u001b[39m=\u001b[39;49maux_kwargs_level,\n\u001b[1;32m    406\u001b[0m         name_suffix\u001b[39m=\u001b[39;49mname_suffix,\n\u001b[1;32m    407\u001b[0m         infer_limit\u001b[39m=\u001b[39;49minfer_limit,\n\u001b[1;32m    408\u001b[0m         infer_limit_batch_size\u001b[39m=\u001b[39;49minfer_limit_batch_size,\n\u001b[1;32m    409\u001b[0m     )\n\u001b[1;32m    410\u001b[0m     model_names_fit \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m base_model_names \u001b[39m+\u001b[39m aux_models\n\u001b[1;32m    411\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel_best \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \u001b[39mlen\u001b[39m(model_names_fit) \u001b[39m!=\u001b[39m \u001b[39m0\u001b[39m:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/autogluon/core/trainer/abstract_trainer.py:539\u001b[0m, in \u001b[0;36mAbstractTrainer.stack_new_level\u001b[0;34m(self, X, y, models, X_val, y_val, X_unlabeled, level, base_model_names, core_kwargs, aux_kwargs, name_suffix, infer_limit, infer_limit_batch_size)\u001b[0m\n\u001b[1;32m    537\u001b[0m     core_kwargs[\u001b[39m\"\u001b[39m\u001b[39mname_suffix\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m core_kwargs\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mname_suffix\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39m+\u001b[39m name_suffix\n\u001b[1;32m    538\u001b[0m     aux_kwargs[\u001b[39m\"\u001b[39m\u001b[39mname_suffix\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m aux_kwargs\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mname_suffix\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39m+\u001b[39m name_suffix\n\u001b[0;32m--> 539\u001b[0m core_models \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstack_new_level_core(\n\u001b[1;32m    540\u001b[0m     X\u001b[39m=\u001b[39;49mX,\n\u001b[1;32m    541\u001b[0m     y\u001b[39m=\u001b[39;49my,\n\u001b[1;32m    542\u001b[0m     X_val\u001b[39m=\u001b[39;49mX_val,\n\u001b[1;32m    543\u001b[0m     y_val\u001b[39m=\u001b[39;49my_val,\n\u001b[1;32m    544\u001b[0m     X_unlabeled\u001b[39m=\u001b[39;49mX_unlabeled,\n\u001b[1;32m    545\u001b[0m     models\u001b[39m=\u001b[39;49mmodels,\n\u001b[1;32m    546\u001b[0m     level\u001b[39m=\u001b[39;49mlevel,\n\u001b[1;32m    547\u001b[0m     infer_limit\u001b[39m=\u001b[39;49minfer_limit,\n\u001b[1;32m    548\u001b[0m     infer_limit_batch_size\u001b[39m=\u001b[39;49minfer_limit_batch_size,\n\u001b[1;32m    549\u001b[0m     base_model_names\u001b[39m=\u001b[39;49mbase_model_names,\n\u001b[1;32m    550\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mcore_kwargs,\n\u001b[1;32m    551\u001b[0m )\n\u001b[1;32m    553\u001b[0m \u001b[39mif\u001b[39;00m X_val \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    554\u001b[0m     aux_models \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstack_new_level_aux(\n\u001b[1;32m    555\u001b[0m         X\u001b[39m=\u001b[39mX, y\u001b[39m=\u001b[39my, base_model_names\u001b[39m=\u001b[39mcore_models, level\u001b[39m=\u001b[39mlevel \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m, infer_limit\u001b[39m=\u001b[39minfer_limit, infer_limit_batch_size\u001b[39m=\u001b[39minfer_limit_batch_size, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39maux_kwargs\n\u001b[1;32m    556\u001b[0m     )\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/autogluon/core/trainer/abstract_trainer.py:673\u001b[0m, in \u001b[0;36mAbstractTrainer.stack_new_level_core\u001b[0;34m(self, X, y, models, X_val, y_val, X_unlabeled, level, base_model_names, stack_name, ag_args, ag_args_fit, ag_args_ensemble, included_model_types, excluded_model_types, ensemble_type, name_suffix, get_models_func, refit_full, infer_limit, infer_limit_batch_size, **kwargs)\u001b[0m\n\u001b[1;32m    670\u001b[0m fit_kwargs \u001b[39m=\u001b[39m \u001b[39mdict\u001b[39m(num_classes\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_classes)\n\u001b[1;32m    672\u001b[0m \u001b[39m# FIXME: TODO: v0.1 X_unlabeled isn't cached so it won't be available during refit_full or fit_extra.\u001b[39;00m\n\u001b[0;32m--> 673\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_train_multi(\n\u001b[1;32m    674\u001b[0m     X\u001b[39m=\u001b[39;49mX_init,\n\u001b[1;32m    675\u001b[0m     y\u001b[39m=\u001b[39;49my,\n\u001b[1;32m    676\u001b[0m     X_val\u001b[39m=\u001b[39;49mX_val,\n\u001b[1;32m    677\u001b[0m     y_val\u001b[39m=\u001b[39;49my_val,\n\u001b[1;32m    678\u001b[0m     X_unlabeled\u001b[39m=\u001b[39;49mX_unlabeled,\n\u001b[1;32m    679\u001b[0m     models\u001b[39m=\u001b[39;49mmodels,\n\u001b[1;32m    680\u001b[0m     level\u001b[39m=\u001b[39;49mlevel,\n\u001b[1;32m    681\u001b[0m     stack_name\u001b[39m=\u001b[39;49mstack_name,\n\u001b[1;32m    682\u001b[0m     compute_score\u001b[39m=\u001b[39;49mcompute_score,\n\u001b[1;32m    683\u001b[0m     fit_kwargs\u001b[39m=\u001b[39;49mfit_kwargs,\n\u001b[1;32m    684\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[1;32m    685\u001b[0m )\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/autogluon/core/trainer/abstract_trainer.py:2321\u001b[0m, in \u001b[0;36mAbstractTrainer._train_multi\u001b[0;34m(self, X, y, models, hyperparameter_tune_kwargs, feature_prune_kwargs, k_fold, n_repeats, n_repeat_start, time_limit, **kwargs)\u001b[0m\n\u001b[1;32m   2319\u001b[0m \u001b[39mif\u001b[39;00m n_repeat_start \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m   2320\u001b[0m     time_start \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[0;32m-> 2321\u001b[0m     model_names_trained \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_train_multi_initial(\n\u001b[1;32m   2322\u001b[0m         X\u001b[39m=\u001b[39;49mX,\n\u001b[1;32m   2323\u001b[0m         y\u001b[39m=\u001b[39;49my,\n\u001b[1;32m   2324\u001b[0m         models\u001b[39m=\u001b[39;49mmodels,\n\u001b[1;32m   2325\u001b[0m         k_fold\u001b[39m=\u001b[39;49mk_fold,\n\u001b[1;32m   2326\u001b[0m         n_repeats\u001b[39m=\u001b[39;49mn_repeats_initial,\n\u001b[1;32m   2327\u001b[0m         hyperparameter_tune_kwargs\u001b[39m=\u001b[39;49mhyperparameter_tune_kwargs,\n\u001b[1;32m   2328\u001b[0m         feature_prune_kwargs\u001b[39m=\u001b[39;49mfeature_prune_kwargs,\n\u001b[1;32m   2329\u001b[0m         time_limit\u001b[39m=\u001b[39;49mtime_limit,\n\u001b[1;32m   2330\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[1;32m   2331\u001b[0m     )\n\u001b[1;32m   2332\u001b[0m     n_repeat_start \u001b[39m=\u001b[39m n_repeats_initial\n\u001b[1;32m   2333\u001b[0m     \u001b[39mif\u001b[39;00m time_limit \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/autogluon/core/trainer/abstract_trainer.py:2170\u001b[0m, in \u001b[0;36mAbstractTrainer._train_multi_initial\u001b[0;34m(self, X, y, models, k_fold, n_repeats, hyperparameter_tune_kwargs, time_limit, feature_prune_kwargs, **kwargs)\u001b[0m\n\u001b[1;32m   2168\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   2169\u001b[0m     time_ratio \u001b[39m=\u001b[39m hpo_time_ratio \u001b[39mif\u001b[39;00m hpo_enabled \u001b[39melse\u001b[39;00m \u001b[39m1\u001b[39m\n\u001b[0;32m-> 2170\u001b[0m     models \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_train_multi_fold(\n\u001b[1;32m   2171\u001b[0m         models\u001b[39m=\u001b[39;49mmodels,\n\u001b[1;32m   2172\u001b[0m         hyperparameter_tune_kwargs\u001b[39m=\u001b[39;49mhyperparameter_tune_kwargs,\n\u001b[1;32m   2173\u001b[0m         k_fold_start\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m,\n\u001b[1;32m   2174\u001b[0m         k_fold_end\u001b[39m=\u001b[39;49mk_fold,\n\u001b[1;32m   2175\u001b[0m         n_repeats\u001b[39m=\u001b[39;49mn_repeats,\n\u001b[1;32m   2176\u001b[0m         n_repeat_start\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m,\n\u001b[1;32m   2177\u001b[0m         time_limit\u001b[39m=\u001b[39;49mtime_limit,\n\u001b[1;32m   2178\u001b[0m         time_split\u001b[39m=\u001b[39;49mtime_split,\n\u001b[1;32m   2179\u001b[0m         time_ratio\u001b[39m=\u001b[39;49mtime_ratio,\n\u001b[1;32m   2180\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_args,\n\u001b[1;32m   2181\u001b[0m     )\n\u001b[1;32m   2183\u001b[0m multi_fold_time_elapsed \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m multi_fold_time_start\n\u001b[1;32m   2184\u001b[0m \u001b[39mif\u001b[39;00m time_limit \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/autogluon/core/trainer/abstract_trainer.py:2278\u001b[0m, in \u001b[0;36mAbstractTrainer._train_multi_fold\u001b[0;34m(self, X, y, models, time_limit, time_split, time_ratio, hyperparameter_tune_kwargs, **kwargs)\u001b[0m\n\u001b[1;32m   2276\u001b[0m         time_start_model \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[1;32m   2277\u001b[0m         time_left \u001b[39m=\u001b[39m time_limit \u001b[39m-\u001b[39m (time_start_model \u001b[39m-\u001b[39m time_start)\n\u001b[0;32m-> 2278\u001b[0m model_name_trained_lst \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_train_single_full(\n\u001b[1;32m   2279\u001b[0m     X, y, model, time_limit\u001b[39m=\u001b[39;49mtime_left, hyperparameter_tune_kwargs\u001b[39m=\u001b[39;49mhyperparameter_tune_kwargs_model, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs\n\u001b[1;32m   2280\u001b[0m )\n\u001b[1;32m   2282\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlow_memory:\n\u001b[1;32m   2283\u001b[0m     \u001b[39mdel\u001b[39;00m model\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/autogluon/core/trainer/abstract_trainer.py:2003\u001b[0m, in \u001b[0;36mAbstractTrainer._train_single_full\u001b[0;34m(self, X, y, model, X_unlabeled, X_val, y_val, X_pseudo, y_pseudo, feature_prune, hyperparameter_tune_kwargs, stack_name, k_fold, k_fold_start, k_fold_end, n_repeats, n_repeat_start, level, time_limit, fit_kwargs, compute_score, total_resources, **kwargs)\u001b[0m\n\u001b[1;32m   1999\u001b[0m     bagged_model_fit_kwargs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_bagged_model_fit_kwargs(\n\u001b[1;32m   2000\u001b[0m         k_fold\u001b[39m=\u001b[39mk_fold, k_fold_start\u001b[39m=\u001b[39mk_fold_start, k_fold_end\u001b[39m=\u001b[39mk_fold_end, n_repeats\u001b[39m=\u001b[39mn_repeats, n_repeat_start\u001b[39m=\u001b[39mn_repeat_start\n\u001b[1;32m   2001\u001b[0m     )\n\u001b[1;32m   2002\u001b[0m     model_fit_kwargs\u001b[39m.\u001b[39mupdate(bagged_model_fit_kwargs)\n\u001b[0;32m-> 2003\u001b[0m     hpo_models, hpo_results \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mhyperparameter_tune(\n\u001b[1;32m   2004\u001b[0m         X\u001b[39m=\u001b[39;49mX,\n\u001b[1;32m   2005\u001b[0m         y\u001b[39m=\u001b[39;49my,\n\u001b[1;32m   2006\u001b[0m         model\u001b[39m=\u001b[39;49mmodel,\n\u001b[1;32m   2007\u001b[0m         X_val\u001b[39m=\u001b[39;49mX_val,\n\u001b[1;32m   2008\u001b[0m         y_val\u001b[39m=\u001b[39;49my_val,\n\u001b[1;32m   2009\u001b[0m         X_unlabeled\u001b[39m=\u001b[39;49mX_unlabeled,\n\u001b[1;32m   2010\u001b[0m         stack_name\u001b[39m=\u001b[39;49mstack_name,\n\u001b[1;32m   2011\u001b[0m         level\u001b[39m=\u001b[39;49mlevel,\n\u001b[1;32m   2012\u001b[0m         compute_score\u001b[39m=\u001b[39;49mcompute_score,\n\u001b[1;32m   2013\u001b[0m         hyperparameter_tune_kwargs\u001b[39m=\u001b[39;49mhyperparameter_tune_kwargs,\n\u001b[1;32m   2014\u001b[0m         total_resources\u001b[39m=\u001b[39;49mtotal_resources,\n\u001b[1;32m   2015\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mmodel_fit_kwargs,\n\u001b[1;32m   2016\u001b[0m     )\n\u001b[1;32m   2017\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   2018\u001b[0m     hpo_models, hpo_results \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mhyperparameter_tune(\n\u001b[1;32m   2019\u001b[0m         X\u001b[39m=\u001b[39mX,\n\u001b[1;32m   2020\u001b[0m         y\u001b[39m=\u001b[39my,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2025\u001b[0m         \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mmodel_fit_kwargs,\n\u001b[1;32m   2026\u001b[0m     )\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/autogluon/core/models/abstract/abstract_model.py:1383\u001b[0m, in \u001b[0;36mAbstractModel.hyperparameter_tune\u001b[0;34m(self, hyperparameter_tune_kwargs, hpo_executor, time_limit, **kwargs)\u001b[0m\n\u001b[1;32m   1381\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvalidate_fit_resources(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m   1382\u001b[0m hpo_executor\u001b[39m.\u001b[39mregister_resources(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m-> 1383\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_hyperparameter_tune(hpo_executor\u001b[39m=\u001b[39;49mhpo_executor, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py:200\u001b[0m, in \u001b[0;36mStackerEnsembleModel._hyperparameter_tune\u001b[0;34m(self, X, y, k_fold, hpo_executor, compute_base_preds, **kwargs)\u001b[0m\n\u001b[1;32m    197\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mself.models must be empty to call hyperparameter_tune, value: \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodels)\n\u001b[1;32m    199\u001b[0m preprocess_kwargs \u001b[39m=\u001b[39m {\u001b[39m\"\u001b[39m\u001b[39mcompute_base_preds\u001b[39m\u001b[39m\"\u001b[39m: compute_base_preds}\n\u001b[0;32m--> 200\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m_hyperparameter_tune(X\u001b[39m=\u001b[39;49mX, y\u001b[39m=\u001b[39;49my, k_fold\u001b[39m=\u001b[39;49mk_fold, hpo_executor\u001b[39m=\u001b[39;49mhpo_executor, preprocess_kwargs\u001b[39m=\u001b[39;49mpreprocess_kwargs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py:1223\u001b[0m, in \u001b[0;36mBaggedEnsembleModel._hyperparameter_tune\u001b[0;34m(self, X, y, X_val, y_val, hpo_executor, k_fold, k_fold_end, **kwargs)\u001b[0m\n\u001b[1;32m   1220\u001b[0m minimum_cpu_per_fold \u001b[39m=\u001b[39m minimum_resources_per_fold\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mnum_cpus\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m1\u001b[39m)\n\u001b[1;32m   1221\u001b[0m minimum_gpu_per_fold \u001b[39m=\u001b[39m minimum_resources_per_fold\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mnum_gpus\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m0\u001b[39m)\n\u001b[0;32m-> 1223\u001b[0m hpo_executor\u001b[39m.\u001b[39;49mexecute(\n\u001b[1;32m   1224\u001b[0m     model_trial\u001b[39m=\u001b[39;49mmodel_trial,\n\u001b[1;32m   1225\u001b[0m     train_fn_kwargs\u001b[39m=\u001b[39;49mtrain_fn_kwargs,\n\u001b[1;32m   1226\u001b[0m     directory\u001b[39m=\u001b[39;49mdirectory,\n\u001b[1;32m   1227\u001b[0m     minimum_cpu_per_trial\u001b[39m=\u001b[39;49mminimum_cpu_per_fold,\n\u001b[1;32m   1228\u001b[0m     minimum_gpu_per_trial\u001b[39m=\u001b[39;49mminimum_gpu_per_fold,\n\u001b[1;32m   1229\u001b[0m     model_estimate_memory_usage\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m,  \u001b[39m# Not needed as we've already calculated it above\u001b[39;49;00m\n\u001b[1;32m   1230\u001b[0m     adapter_type\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mtabular\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m   1231\u001b[0m     trainable_is_parallel\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m   1232\u001b[0m     tune_config_kwargs\u001b[39m=\u001b[39;49m{\u001b[39m\"\u001b[39;49m\u001b[39mchdir_to_trial_dir\u001b[39;49m\u001b[39m\"\u001b[39;49m: \u001b[39mFalse\u001b[39;49;00m},\n\u001b[1;32m   1233\u001b[0m )\n\u001b[1;32m   1235\u001b[0m hpo_results \u001b[39m=\u001b[39m hpo_executor\u001b[39m.\u001b[39mget_hpo_results(\n\u001b[1;32m   1236\u001b[0m     model_name\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mname,\n\u001b[1;32m   1237\u001b[0m     model_path_root\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpath_root,\n\u001b[1;32m   1238\u001b[0m     time_start\u001b[39m=\u001b[39mtime_start,\n\u001b[1;32m   1239\u001b[0m )\n\u001b[1;32m   1241\u001b[0m \u001b[39mreturn\u001b[39;00m hpo_results\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/autogluon/core/hpo/executors.py:528\u001b[0m, in \u001b[0;36mCustomHpoExecutor.execute\u001b[0;34m(self, model_trial, train_fn_kwargs, **kwargs)\u001b[0m\n\u001b[1;32m    525\u001b[0m scheduler \u001b[39m=\u001b[39m scheduler_cls(model_trial, search_space\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msearch_space, train_fn_kwargs\u001b[39m=\u001b[39mtrain_fn_kwargs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mscheduler_params)\n\u001b[1;32m    526\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mscheduler \u001b[39m=\u001b[39m scheduler\n\u001b[0;32m--> 528\u001b[0m scheduler\u001b[39m.\u001b[39;49mrun()\n\u001b[1;32m    529\u001b[0m scheduler\u001b[39m.\u001b[39mjoin_jobs()\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/autogluon/core/scheduler/seq_scheduler.py:158\u001b[0m, in \u001b[0;36mLocalSequentialScheduler.run\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    156\u001b[0m trial_start_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[1;32m    157\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 158\u001b[0m     is_failed, result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrun_trial(task_id\u001b[39m=\u001b[39;49mi)\n\u001b[1;32m    159\u001b[0m \u001b[39mexcept\u001b[39;00m ExhaustedSearchSpaceError:\n\u001b[1;32m    160\u001b[0m     \u001b[39mbreak\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/autogluon/core/scheduler/seq_scheduler.py:258\u001b[0m, in \u001b[0;36mLocalSequentialScheduler.run_trial\u001b[0;34m(self, task_id)\u001b[0m\n\u001b[1;32m    256\u001b[0m searcher_config\u001b[39m.\u001b[39mupdate(new_searcher_config)\n\u001b[1;32m    257\u001b[0m reporter \u001b[39m=\u001b[39m LocalReporter(task_id, searcher_config, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtraining_history, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig_history)\n\u001b[0;32m--> 258\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrun_job_(task_id, searcher_config, reporter)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/autogluon/core/scheduler/seq_scheduler.py:274\u001b[0m, in \u001b[0;36mLocalSequentialScheduler.run_job_\u001b[0;34m(self, task_id, searcher_config, reporter)\u001b[0m\n\u001b[1;32m    272\u001b[0m is_failed \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m    273\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 274\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_fn(args, reporter\u001b[39m=\u001b[39;49mreporter, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mtrain_fn_kwargs)\n\u001b[1;32m    275\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mtype\u001b[39m(reporter) \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m FakeReporter:\n\u001b[1;32m    276\u001b[0m         \u001b[39mif\u001b[39;00m reporter\u001b[39m.\u001b[39mlast_result:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/autogluon/core/models/abstract/model_trial.py:37\u001b[0m, in \u001b[0;36mmodel_trial\u001b[0;34m(args, model_cls, init_params, train_path, val_path, time_start, hpo_executor, is_bagged_model, reporter, time_limit, fit_kwargs)\u001b[0m\n\u001b[1;32m     35\u001b[0m     fit_model_args \u001b[39m=\u001b[39m \u001b[39mdict\u001b[39m(X\u001b[39m=\u001b[39mX, y\u001b[39m=\u001b[39my, X_val\u001b[39m=\u001b[39mX_val, y_val\u001b[39m=\u001b[39my_val, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_kwargs)\n\u001b[1;32m     36\u001b[0m     predict_proba_args \u001b[39m=\u001b[39m \u001b[39mdict\u001b[39m(X\u001b[39m=\u001b[39mX_val)\n\u001b[0;32m---> 37\u001b[0m     model \u001b[39m=\u001b[39m fit_and_save_model(\n\u001b[1;32m     38\u001b[0m         model\u001b[39m=\u001b[39;49mmodel,\n\u001b[1;32m     39\u001b[0m         fit_args\u001b[39m=\u001b[39;49mfit_model_args,\n\u001b[1;32m     40\u001b[0m         predict_proba_args\u001b[39m=\u001b[39;49mpredict_proba_args,\n\u001b[1;32m     41\u001b[0m         y_val\u001b[39m=\u001b[39;49my_val,\n\u001b[1;32m     42\u001b[0m         time_start\u001b[39m=\u001b[39;49mtime_start,\n\u001b[1;32m     43\u001b[0m         time_limit\u001b[39m=\u001b[39;49mtime_limit,\n\u001b[1;32m     44\u001b[0m     )\n\u001b[1;32m     45\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     46\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(e, TimeLimitExceeded):\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/autogluon/core/models/abstract/model_trial.py:96\u001b[0m, in \u001b[0;36mfit_and_save_model\u001b[0;34m(model, fit_args, predict_proba_args, y_val, time_start, time_limit)\u001b[0m\n\u001b[1;32m     93\u001b[0m     time_left \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     95\u001b[0m time_fit_start \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[0;32m---> 96\u001b[0m model\u001b[39m.\u001b[39;49mfit(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_args, time_limit\u001b[39m=\u001b[39;49mtime_left)\n\u001b[1;32m     97\u001b[0m time_fit_end \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[1;32m     99\u001b[0m \u001b[39mif\u001b[39;00m model\u001b[39m.\u001b[39m_get_tags()\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mvalid_oof\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mFalse\u001b[39;00m):\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/autogluon/core/models/abstract/abstract_model.py:829\u001b[0m, in \u001b[0;36mAbstractModel.fit\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    827\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvalidate_fit_resources(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    828\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_fit_memory_usage(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m--> 829\u001b[0m out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fit(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    830\u001b[0m \u001b[39mif\u001b[39;00m out \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    831\u001b[0m     out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py:169\u001b[0m, in \u001b[0;36mStackerEnsembleModel._fit\u001b[0;34m(self, X, y, compute_base_preds, time_limit, **kwargs)\u001b[0m\n\u001b[1;32m    167\u001b[0m \u001b[39mif\u001b[39;00m time_limit \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    168\u001b[0m     time_limit \u001b[39m=\u001b[39m time_limit \u001b[39m-\u001b[39m (time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m start_time)\n\u001b[0;32m--> 169\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m_fit(X\u001b[39m=\u001b[39;49mX, y\u001b[39m=\u001b[39;49my, time_limit\u001b[39m=\u001b[39;49mtime_limit, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py:266\u001b[0m, in \u001b[0;36mBaggedEnsembleModel._fit\u001b[0;34m(self, X, y, X_val, y_val, X_pseudo, y_pseudo, k_fold, k_fold_start, k_fold_end, n_repeats, n_repeat_start, groups, _skip_oof, **kwargs)\u001b[0m\n\u001b[1;32m    264\u001b[0m         \u001b[39m# Reserve time for final refit model\u001b[39;00m\n\u001b[1;32m    265\u001b[0m         kwargs[\u001b[39m\"\u001b[39m\u001b[39mtime_limit\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m kwargs[\u001b[39m\"\u001b[39m\u001b[39mtime_limit\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m*\u001b[39m folds_to_fit \u001b[39m/\u001b[39m (folds_to_fit \u001b[39m+\u001b[39m \u001b[39m1.2\u001b[39m)\n\u001b[0;32m--> 266\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fit_folds(\n\u001b[1;32m    267\u001b[0m     X\u001b[39m=\u001b[39;49mX,\n\u001b[1;32m    268\u001b[0m     y\u001b[39m=\u001b[39;49my,\n\u001b[1;32m    269\u001b[0m     model_base\u001b[39m=\u001b[39;49mmodel_base,\n\u001b[1;32m    270\u001b[0m     X_pseudo\u001b[39m=\u001b[39;49mX_pseudo,\n\u001b[1;32m    271\u001b[0m     y_pseudo\u001b[39m=\u001b[39;49my_pseudo,\n\u001b[1;32m    272\u001b[0m     k_fold\u001b[39m=\u001b[39;49mk_fold,\n\u001b[1;32m    273\u001b[0m     k_fold_start\u001b[39m=\u001b[39;49mk_fold_start,\n\u001b[1;32m    274\u001b[0m     k_fold_end\u001b[39m=\u001b[39;49mk_fold_end,\n\u001b[1;32m    275\u001b[0m     n_repeats\u001b[39m=\u001b[39;49mn_repeats,\n\u001b[1;32m    276\u001b[0m     n_repeat_start\u001b[39m=\u001b[39;49mn_repeat_start,\n\u001b[1;32m    277\u001b[0m     save_folds\u001b[39m=\u001b[39;49msave_bag_folds,\n\u001b[1;32m    278\u001b[0m     groups\u001b[39m=\u001b[39;49mgroups,\n\u001b[1;32m    279\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[1;32m    280\u001b[0m )\n\u001b[1;32m    281\u001b[0m \u001b[39m# FIXME: Cleanup self\u001b[39;00m\n\u001b[1;32m    282\u001b[0m \u001b[39m# FIXME: Support `can_refit_full=False` models\u001b[39;00m\n\u001b[1;32m    283\u001b[0m \u001b[39mif\u001b[39;00m refit_folds:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py:592\u001b[0m, in \u001b[0;36mBaggedEnsembleModel._fit_folds\u001b[0;34m(self, X, y, model_base, X_pseudo, y_pseudo, k_fold, k_fold_start, k_fold_end, n_repeats, n_repeat_start, time_limit, sample_weight, save_folds, groups, num_cpus, num_gpus, **kwargs)\u001b[0m\n\u001b[1;32m    590\u001b[0m \u001b[39mfor\u001b[39;00m fold_fit_args \u001b[39min\u001b[39;00m fold_fit_args_list:\n\u001b[1;32m    591\u001b[0m     fold_fitting_strategy\u001b[39m.\u001b[39mschedule_fold_model_fit(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfold_fit_args)\n\u001b[0;32m--> 592\u001b[0m fold_fitting_strategy\u001b[39m.\u001b[39;49mafter_all_folds_scheduled()\n\u001b[1;32m    594\u001b[0m \u001b[39mfor\u001b[39;00m model \u001b[39min\u001b[39;00m models:\n\u001b[1;32m    595\u001b[0m     \u001b[39m# No need to add child times or save child here as this already occurred in the fold_fitting_strategy\u001b[39;00m\n\u001b[1;32m    596\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39madd_child(model\u001b[39m=\u001b[39mmodel, add_child_times\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py:538\u001b[0m, in \u001b[0;36mParallelFoldFittingStrategy.after_all_folds_scheduled\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    536\u001b[0m unfinished \u001b[39m=\u001b[39m job_refs\n\u001b[1;32m    537\u001b[0m \u001b[39mwhile\u001b[39;00m unfinished:\n\u001b[0;32m--> 538\u001b[0m     finished, unfinished \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mray\u001b[39m.\u001b[39;49mwait(unfinished, num_returns\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m)\n\u001b[1;32m    539\u001b[0m     finished \u001b[39m=\u001b[39m finished[\u001b[39m0\u001b[39m]\n\u001b[1;32m    540\u001b[0m     \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/ray/_private/client_mode_hook.py:105\u001b[0m, in \u001b[0;36mclient_mode_hook.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    103\u001b[0m     \u001b[39mif\u001b[39;00m func\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39minit\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mor\u001b[39;00m is_client_mode_enabled_by_default:\n\u001b[1;32m    104\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mgetattr\u001b[39m(ray, func\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m)(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m--> 105\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/ray/_private/worker.py:2578\u001b[0m, in \u001b[0;36mwait\u001b[0;34m(object_refs, num_returns, timeout, fetch_local)\u001b[0m\n\u001b[1;32m   2576\u001b[0m timeout \u001b[39m=\u001b[39m timeout \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39m10\u001b[39m\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39m6\u001b[39m\n\u001b[1;32m   2577\u001b[0m timeout_milliseconds \u001b[39m=\u001b[39m \u001b[39mint\u001b[39m(timeout \u001b[39m*\u001b[39m \u001b[39m1000\u001b[39m)\n\u001b[0;32m-> 2578\u001b[0m ready_ids, remaining_ids \u001b[39m=\u001b[39m worker\u001b[39m.\u001b[39;49mcore_worker\u001b[39m.\u001b[39;49mwait(\n\u001b[1;32m   2579\u001b[0m     object_refs,\n\u001b[1;32m   2580\u001b[0m     num_returns,\n\u001b[1;32m   2581\u001b[0m     timeout_milliseconds,\n\u001b[1;32m   2582\u001b[0m     worker\u001b[39m.\u001b[39;49mcurrent_task_id,\n\u001b[1;32m   2583\u001b[0m     fetch_local,\n\u001b[1;32m   2584\u001b[0m )\n\u001b[1;32m   2585\u001b[0m \u001b[39mreturn\u001b[39;00m ready_ids, remaining_ids\n",
      "File \u001b[0;32mpython/ray/_raylet.pyx:1833\u001b[0m, in \u001b[0;36mray._raylet.CoreWorker.wait\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpython/ray/_raylet.pyx:199\u001b[0m, in \u001b[0;36mray._raylet.check_status\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "df = ml.data.get_training_cleaned()\n",
    "\n",
    "for location in ['A']:#, 'B', 'C']:\n",
    "    print(\"###########################################\")\n",
    "    print(f\"###############  LOCATION {location} ###############\")\n",
    "    print(\"###########################################\")\n",
    "    df_location = df[df['location'] == location]\n",
    "\n",
    "    agh = AutoGluonJacob()\n",
    "    agh.test(df_location, n_splits=2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results\n",
    "\n",
    "    self.params_TabularPredictor = \\\n",
    "        {\n",
    "            'label': 'y',\n",
    "            'problem_type': 'regression', \n",
    "            'eval_metric': 'mean_absolute_error',\n",
    "            'verbosity': 0,\n",
    "            'sample_weight': None\n",
    "        } \n",
    "    # TabularPredictor.fit\n",
    "    self.params_TabularPredictor_fit = \\\n",
    "        {\n",
    "            'time_limit': 60,\n",
    "            'presets': 'good_quality', # [‘best_quality’, ‘high_quality’, ‘good_quality’, ‘medium_quality’, ‘optimize_for_deployment’, ‘interpretable’, ‘ignore_text’]\n",
    "            'hyperparameters': 'default',\n",
    "            # 'auto_stack': False,\n",
    "            # 'num_bag_folds': None, # set automatically by auto_stack True\n",
    "            # 'num_bag_sets': None, # set to 20 because of auto_stack\n",
    "            # 'num_stack_levels': None, # set automatically by auto_stack True\n",
    "            # 'hyperparameter_tune_kwargs': 'random', # None to disable\n",
    "            # 'refit_full': True,\n",
    "            # 'feature_prune_kwargs': None#{}, # If None, do not perform feature pruning. If empty dictionary, perform feature pruning with default configurations.\n",
    "        }\n",
    "\n",
    "    self.use_tuning_data = False\n",
    "MAE Vals: MEAN: 164.62250084174644 ALL: [164.31157948281893, 164.933422200674]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "    self.use_tuning_data = True\n",
    "    tuning_data = temp_df.sample(frac=0.05, random_state=42)\n",
    "MAE Vals: MEAN: 166.73566744849495 ALL: [168.50105388270137, 164.97028101428853]\n",
    "\n",
    "    sample seed 142\n",
    "MAE Vals: MEAN: 165.69652975339554 ALL: [167.9125409043826, 163.48051860240847]\n",
    "\n",
    "    sample seed 42\n",
    "    self.use_tuning_data = False\n",
    "    sample_weight = True\n",
    "MAE Vals: MEAN: 166.19670395329996 ALL: [167.63860398559584, 164.75480392100408]\n",
    "\n",
    "    self.use_tuning_data = True\n",
    "    tuning_data = temp_df[(temp_df['month'] == 5) | (temp_df['month'] == 6)].sample(frac=0.05, random_state=142)\n",
    "    sample_weight = True\n",
    "MAE Vals: MEAN: 167.18372152573014 ALL: [170.1052116231583, 164.26223142830196]\n",
    "\n",
    "    'feature_prune_kwargs': {}\n",
    "MAE Vals: MEAN: 166.19423848616486 ALL: [168.88409245902324, 163.50438451330652]\n",
    "\n",
    "#### Switch to seeded KFold\n",
    "\n",
    "    'hyperparameter_tune_kwargs': 'random'\n",
    "MAE Vals: MEAN: 175.01220468483484 ALL: [177.53382030663508, 172.49058906303463]\n",
    "\n",
    "    'feature_prune_kwargs': None\n",
    "    self.use_tuning_data = False\n",
    "    self.use_sample_weight = False\n",
    "MAE Vals: MEAN: 172.1411154741047 ALL: [172.74787350507623, 171.5343574431332]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "    'hyperparameter_tune_kwargs': None\n",
    "MAE Vals: MEAN: 165.01777919495962 ALL: [165.55820916266555, 164.47734922725368]\n",
    "\n",
    "    'feature_prune_kwargs': {}\n",
    "MAE Vals: MEAN: 165.0372890394286 ALL: [165.5598301875853, 164.5147478912719]\n",
    "\n",
    "    'time_limit': 180,\n",
    "MAE Vals: MEAN: 165.37766162641057 ALL: [164.87359981161345, 165.8817234412077]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUTOGLUON MODEL OVERVIEW:\n",
      "['KNeighborsUnif_BAG_L1', 'KNeighborsDist_BAG_L1', 'LightGBMXT_BAG_L1/T1', 'LightGBM_BAG_L1/T1', 'RandomForestMSE_BAG_L1', 'CatBoost_BAG_L1/T1', 'ExtraTreesMSE_BAG_L1', 'XGBoost_BAG_L1/T1', 'LightGBMLarge_BAG_L1', 'WeightedEnsemble_L2', 'LightGBMXT_BAG_L2/T1', 'LightGBM_BAG_L2/T1', 'CatBoost_BAG_L2/T1', 'ExtraTreesMSE_BAG_L2', 'XGBoost_BAG_L2/T1', 'LightGBMLarge_BAG_L2', 'WeightedEnsemble_L3', 'KNeighborsUnif_BAG_L1_FULL', 'KNeighborsDist_BAG_L1_FULL', 'LightGBMXT_BAG_L1/T1_FULL', 'LightGBM_BAG_L1/T1_FULL', 'RandomForestMSE_BAG_L1_FULL', 'CatBoost_BAG_L1/T1_FULL', 'ExtraTreesMSE_BAG_L1_FULL', 'XGBoost_BAG_L1/T1_FULL', 'LightGBMLarge_BAG_L1_FULL', 'WeightedEnsemble_L2_FULL', 'LightGBMXT_BAG_L2/T1_FULL', 'LightGBM_BAG_L2/T1_FULL', 'CatBoost_BAG_L2/T1_FULL', 'ExtraTreesMSE_BAG_L2_FULL', 'XGBoost_BAG_L2/T1_FULL', 'LightGBMLarge_BAG_L2_FULL', 'WeightedEnsemble_L3_FULL']\n"
     ]
    }
   ],
   "source": [
    "ml.utils.make_submittable(\"GluonW_HPO_and_tuning_data_and_sample_weighting_2x.csv\", model=AutoGluonJacob())\n",
    "\n",
    "# df = pd.read_csv(ml.module_dir + '/../submissions/GluonW_HPO_and_tuning_data.csv').merge(pd.read_csv(ml.module_dir + '/../submissions/XGBoostComposite_laptop.csv'), left_index=True, right_index=True)\n",
    "# abs(df.prediction_x - df.prediction_y).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
