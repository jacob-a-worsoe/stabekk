{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing notebook, remove bad points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Get the absolute path of parent folder\n",
    "current_dir = os.path.abspath(\"\")\n",
    "parent_dir = os.path.join(current_dir, os.pardir)\n",
    "\n",
    "# Add to sys.path\n",
    "sys.path.append(parent_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ml_combat as ml\n",
    "from ml_combat import data\n",
    "from ml_combat.MetaModel import MetaModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from prophet import Prophet\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogluon.tabular import TabularDataset, TabularPredictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class AutoGluonJacob(MetaModel):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__(\"AutoGluon Jacob\")\n",
    "\n",
    "        # autogluon features\n",
    "        # TabularPredictor (usage : **params_TabularPredictor)\n",
    "        self.params_TabularPredictor = \\\n",
    "            {\n",
    "                'label': 'y',\n",
    "                'problem_type': 'regression', \n",
    "                'eval_metric': 'mean_absolute_error',\n",
    "                'verbosity': 1,\n",
    "            } \n",
    "        # TabularPredictor.fit\n",
    "        self.params_TabularPredictor_fit = \\\n",
    "            {\n",
    "                'time_limit': 60*5,\n",
    "                'presets': 'high_quality', # [‘best_quality’, ‘high_quality’, ‘good_quality’, ‘medium_quality’, ‘optimize_for_deployment’, ‘interpretable’, ‘ignore_text’]\n",
    "                'hyperparameters': 'default',\n",
    "                # 'auto_stack': False,\n",
    "                # 'num_bag_folds': None, # set automatically by auto_stack True\n",
    "                # 'num_bag_sets': None, # set to 20 because of auto_stack\n",
    "                # 'num_stack_levels': 3, # set automatically by auto_stack True\n",
    "                'hyperparameter_tune_kwargs': 'auto', # None to disable\n",
    "                # 'refit_full': True,\n",
    "                # 'feature_prune_kwargs': {}, # If None, do not perform feature pruning. If empty dictionary, perform feature pruning with default configurations.\n",
    "            }\n",
    "\n",
    "        self.use_tuning_data = True # 'sample_weight', 'random'\n",
    "        self.use_sample_weight = False\n",
    "\n",
    "        if self.use_sample_weight: # auto_weight a feature that exists\n",
    "            self.params_TabularPredictor['sample_weight'] = 'sample_importance'\n",
    "        \n",
    "\n",
    "    def preprocess(self, df: pd.DataFrame):\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        temp_df = df.copy()\n",
    "\n",
    "        temp_df['total_rad_1h:J'] = temp_df['diffuse_rad_1h:J'] + temp_df['direct_rad_1h:J']    \n",
    "        \n",
    "        # Extracting hour-of-day and month, and making them cyclical\n",
    "        temp_df['hour'] = temp_df['ds'].dt.hour\n",
    "        temp_df['hour'] = (np.sin(2 * np.pi * (temp_df['hour'] - 4)/ 24) + 1) / 2\n",
    "\n",
    "        temp_df['dayofyear'] = temp_df['ds'].dt.day_of_year\n",
    "        temp_df['dayofyear'] = np.sin(2 * np.pi * (temp_df['dayofyear'] - 80)/ 365)\n",
    "\n",
    "        # temp_df['year'] = temp_df['ds'].dt.hour\n",
    "        temp_df['month'] = temp_df['ds'].dt.month\n",
    "        # temp_df['day'] = temp_df['ds'].dt.day\n",
    "        # temp_df['dayofweek'] = temp_df['ds'].dt.dayofweek\n",
    "\n",
    "        if self.use_sample_weight:\n",
    "            # Emphasize test start-end: Starting date: 2023-05-01 00:00:00 Ending data 2023-07-03 23:00:00\n",
    "            temp_df['sample_importance'] = 1\n",
    "            temp_df.loc[(temp_df['ds'].dt.month >= 5) & \n",
    "                        (temp_df['ds'].dt.month < 7), 'sample_importance'] = 2\n",
    "            \n",
    "            # temp_df.loc[(temp_df['ds'].dt.month == 7) &\n",
    "            #             (temp_df['ds'].dt.day <= 4), 'sample_importance'] = 2\n",
    "\n",
    "\n",
    "\n",
    "        return temp_df.drop(columns=['ds'])\n",
    "\n",
    "    def train(self, df):\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        temp_df = self.preprocess(df)\n",
    "\n",
    "        if self.use_tuning_data:\n",
    "\n",
    "            # tuning_data = temp_df[(temp_df['month'] == 5) | (temp_df['month'] == 6)].sample(frac=0.5, random_state=42)\n",
    "            # train_data = TabularDataset(temp_df[~temp_df.isin(tuning_data.to_dict(orient='list')).all(1)])\n",
    "            train_data, tuning_data = train_test_split(df, test_size=0.1, random_state=42)\n",
    "            train_data = TabularDataset(train_data)\n",
    "\n",
    "            self.model = TabularPredictor(**self.params_TabularPredictor).fit(train_data, tuning_data=tuning_data, use_bag_holdout=True, **self.params_TabularPredictor_fit)\n",
    "        else:\n",
    "            train_data = TabularDataset(temp_df)\n",
    "\n",
    "            self.model = TabularPredictor(**self.params_TabularPredictor).fit(train_data, **self.params_TabularPredictor_fit)\n",
    "\n",
    "    def predict(self, df):\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        df = self.preprocess(df)\n",
    "\n",
    "        features = [col for col in df.columns if col != 'y']\n",
    "        X = df[features]\n",
    "\n",
    "\n",
    "\n",
    "        y_preds = self.model.predict(X)\n",
    "        print(\"AUTOGLUON MODEL OVERVIEW:\")\n",
    "        print(self.model.leaderboard())\n",
    "       \n",
    "\n",
    "        out_df = pd.DataFrame(data={'y_pred': y_preds})\n",
    "\n",
    "        return out_df\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# df = ml.data.get_training_cleaned()\n",
    "\n",
    "# for location in ['A']:#, 'B', 'C']:\n",
    "#     print(\"###########################################\")\n",
    "#     print(f\"###############  LOCATION {location} ###############\")\n",
    "#     print(\"###########################################\")\n",
    "#     df_location = df[df['location'] == location]\n",
    "\n",
    "#     agh = AutoGluonJacob()\n",
    "#     agh.test(df_location, n_splits=2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results\n",
    "\n",
    "    self.params_TabularPredictor = \\\n",
    "        {\n",
    "            'label': 'y',\n",
    "            'problem_type': 'regression', \n",
    "            'eval_metric': 'mean_absolute_error',\n",
    "            'verbosity': 0,\n",
    "            'sample_weight': None\n",
    "        } \n",
    "    # TabularPredictor.fit\n",
    "    self.params_TabularPredictor_fit = \\\n",
    "        {\n",
    "            'time_limit': 60,\n",
    "            'presets': 'good_quality', # [‘best_quality’, ‘high_quality’, ‘good_quality’, ‘medium_quality’, ‘optimize_for_deployment’, ‘interpretable’, ‘ignore_text’]\n",
    "            'hyperparameters': 'default',\n",
    "            # 'auto_stack': False,\n",
    "            # 'num_bag_folds': None, # set automatically by auto_stack True\n",
    "            # 'num_bag_sets': None, # set to 20 because of auto_stack\n",
    "            # 'num_stack_levels': None, # set automatically by auto_stack True\n",
    "            # 'hyperparameter_tune_kwargs': 'random', # None to disable\n",
    "            # 'refit_full': True,\n",
    "            # 'feature_prune_kwargs': None#{}, # If None, do not perform feature pruning. If empty dictionary, perform feature pruning with default configurations.\n",
    "        }\n",
    "\n",
    "    self.use_tuning_data = False\n",
    "MAE Vals: MEAN: 164.62250084174644 ALL: [164.31157948281893, 164.933422200674]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "    self.use_tuning_data = True\n",
    "    tuning_data = temp_df.sample(frac=0.05, random_state=42)\n",
    "MAE Vals: MEAN: 166.73566744849495 ALL: [168.50105388270137, 164.97028101428853]\n",
    "\n",
    "    sample seed 142\n",
    "MAE Vals: MEAN: 165.69652975339554 ALL: [167.9125409043826, 163.48051860240847]\n",
    "\n",
    "    sample seed 42\n",
    "    self.use_tuning_data = False\n",
    "    sample_weight = True\n",
    "MAE Vals: MEAN: 166.19670395329996 ALL: [167.63860398559584, 164.75480392100408]\n",
    "\n",
    "    self.use_tuning_data = True\n",
    "    tuning_data = temp_df[(temp_df['month'] == 5) | (temp_df['month'] == 6)].sample(frac=0.05, random_state=142)\n",
    "    sample_weight = True\n",
    "MAE Vals: MEAN: 167.18372152573014 ALL: [170.1052116231583, 164.26223142830196]\n",
    "\n",
    "    'feature_prune_kwargs': {}\n",
    "MAE Vals: MEAN: 166.19423848616486 ALL: [168.88409245902324, 163.50438451330652]\n",
    "\n",
    "#### Switch to seeded KFold\n",
    "\n",
    "    'hyperparameter_tune_kwargs': 'random'\n",
    "MAE Vals: MEAN: 175.01220468483484 ALL: [177.53382030663508, 172.49058906303463]\n",
    "\n",
    "    'feature_prune_kwargs': None\n",
    "    self.use_tuning_data = False\n",
    "    self.use_sample_weight = False\n",
    "MAE Vals: MEAN: 172.1411154741047 ALL: [172.74787350507623, 171.5343574431332]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "    'hyperparameter_tune_kwargs': None\n",
    "MAE Vals: MEAN: 165.01777919495962 ALL: [165.55820916266555, 164.47734922725368]\n",
    "\n",
    "    'feature_prune_kwargs': {}\n",
    "MAE Vals: MEAN: 165.0372890394286 ALL: [165.5598301875853, 164.5147478912719]\n",
    "\n",
    "    'time_limit': 180,\n",
    "MAE Vals: MEAN: 165.37766162641057 ALL: [164.87359981161345, 165.8817234412077]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was trained during hyperparameter tuning NeuralNetTorch_BAG_L2... Skipping this model.\n",
      "\tWarning: Reducing model 'n_estimators' from 209 -> 183 due to low memory. Expected memory usage reduced from 17.06% -> 15.0% of available memory...\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"1 required columns are missing from the provided dataset to transform using AutoMLPipelineFeatureGenerator. 1 missing columns: ['ds'] | 51 available columns: ['location', 'weather_data_type', 'absolute_humidity_2m:gm3', 'air_density_2m:kgm3', 'ceiling_height_agl:m', 'clear_sky_energy_1h:J', 'clear_sky_rad:W', 'cloud_base_agl:m', 'dew_or_rime:idx', 'dew_point_2m:K', 'diffuse_rad:W', 'diffuse_rad_1h:J', 'direct_rad:W', 'direct_rad_1h:J', 'effective_cloud_cover:p', 'elevation:m', 'fresh_snow_12h:cm', 'fresh_snow_1h:cm', 'fresh_snow_24h:cm', 'fresh_snow_3h:cm', 'fresh_snow_6h:cm', 'is_day:idx', 'is_in_shadow:idx', 'msl_pressure:hPa', 'precip_5min:mm', 'precip_type_5min:idx', 'pressure_100m:hPa', 'pressure_50m:hPa', 'prob_rime:p', 'rain_water:kgm2', 'relative_humidity_1000hPa:p', 'sfc_pressure:hPa', 'snow_density:kgm3', 'snow_depth:cm', 'snow_drift:idx', 'snow_melt_10min:mm', 'snow_water:kgm2', 'sun_azimuth:d', 'sun_elevation:d', 'super_cooled_liquid_water:kgm2', 't_1000hPa:K', 'total_cloud_cover:p', 'visibility:m', 'wind_speed_10m:ms', 'wind_speed_u_10m:ms', 'wind_speed_v_10m:ms', 'wind_speed_w_1000hPa:ms', 'total_rad_1h:J', 'hour', 'dayofyear', 'month']\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/autogluon/features/generators/abstract.py:338\u001b[0m, in \u001b[0;36mAbstractFeatureGenerator.transform\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    335\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mlist\u001b[39m(X\u001b[39m.\u001b[39mcolumns) \u001b[39m!=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfeatures_in:\n\u001b[1;32m    336\u001b[0m         \u001b[39m# It comes at a cost when making a copy of the DataFrame,\u001b[39;00m\n\u001b[1;32m    337\u001b[0m         \u001b[39m# therefore, try avoid copying by checking the expected features first.\u001b[39;00m\n\u001b[0;32m--> 338\u001b[0m         X \u001b[39m=\u001b[39m X[\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfeatures_in]\n\u001b[1;32m    339\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pandas/core/frame.py:3811\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3810\u001b[0m         key \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(key)\n\u001b[0;32m-> 3811\u001b[0m     indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcolumns\u001b[39m.\u001b[39;49m_get_indexer_strict(key, \u001b[39m\"\u001b[39;49m\u001b[39mcolumns\u001b[39;49m\u001b[39m\"\u001b[39;49m)[\u001b[39m1\u001b[39m]\n\u001b[1;32m   3813\u001b[0m \u001b[39m# take() does not accept boolean indexers\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pandas/core/indexes/base.py:6108\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[0;34m(self, key, axis_name)\u001b[0m\n\u001b[1;32m   6106\u001b[0m     keyarr, indexer, new_indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[0;32m-> 6108\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_raise_if_missing(keyarr, indexer, axis_name)\n\u001b[1;32m   6110\u001b[0m keyarr \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtake(indexer)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pandas/core/indexes/base.py:6171\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[0;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[1;32m   6170\u001b[0m not_found \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[39m.\u001b[39mnonzero()[\u001b[39m0\u001b[39m]]\u001b[39m.\u001b[39munique())\n\u001b[0;32m-> 6171\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mnot_found\u001b[39m}\u001b[39;00m\u001b[39m not in index\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mKeyError\u001b[0m: \"['ds'] not in index\"",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m/Users/jacobworsoe/Documents/H23/Maskinlæring/stabekk/notebooks/autogluon_valid.ipynb Cell 12\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/jacobworsoe/Documents/H23/Maskinl%C3%A6ring/stabekk/notebooks/autogluon_valid.ipynb#X14sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m ml\u001b[39m.\u001b[39;49mutils\u001b[39m.\u001b[39;49mmake_submittable(\u001b[39m\"\u001b[39;49m\u001b[39mGluonW_HPO_and_tuning_data_train_test_split.csv\u001b[39;49m\u001b[39m\"\u001b[39;49m, model\u001b[39m=\u001b[39;49mAutoGluonJacob())\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/jacobworsoe/Documents/H23/Maskinl%C3%A6ring/stabekk/notebooks/autogluon_valid.ipynb#X14sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39m# df = pd.read_csv(ml.module_dir + '/../submissions/GluonW_HPO_and_tuning_data.csv').merge(pd.read_csv(ml.module_dir + '/../submissions/XGBoostComposite_laptop.csv'), left_index=True, right_index=True)\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/jacobworsoe/Documents/H23/Maskinl%C3%A6ring/stabekk/notebooks/autogluon_valid.ipynb#X14sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39m# abs(df.prediction_x - df.prediction_y).mean()\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/H23/Maskinlæring/stabekk/notebooks/../ml_combat/utils.py:71\u001b[0m, in \u001b[0;36mmake_submittable\u001b[0;34m(file_name, model, model_dict)\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mno model specified\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     70\u001b[0m     m\u001b[39m.\u001b[39mtrain(temp_df)\n\u001b[0;32m---> 71\u001b[0m     fcst \u001b[39m=\u001b[39m m\u001b[39m.\u001b[39;49mpredict(temp_test)\n\u001b[1;32m     73\u001b[0m     ret \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mconcat([ret, fcst])\n\u001b[1;32m     75\u001b[0m y_pred_to_csv(file_name, ret)\n",
      "\u001b[1;32m/Users/jacobworsoe/Documents/H23/Maskinlæring/stabekk/notebooks/autogluon_valid.ipynb Cell 12\u001b[0m line \u001b[0;36m9\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jacobworsoe/Documents/H23/Maskinl%C3%A6ring/stabekk/notebooks/autogluon_valid.ipynb#X14sZmlsZQ%3D%3D?line=91'>92</a>\u001b[0m features \u001b[39m=\u001b[39m [col \u001b[39mfor\u001b[39;00m col \u001b[39min\u001b[39;00m df\u001b[39m.\u001b[39mcolumns \u001b[39mif\u001b[39;00m col \u001b[39m!=\u001b[39m \u001b[39m'\u001b[39m\u001b[39my\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jacobworsoe/Documents/H23/Maskinl%C3%A6ring/stabekk/notebooks/autogluon_valid.ipynb#X14sZmlsZQ%3D%3D?line=92'>93</a>\u001b[0m X \u001b[39m=\u001b[39m df[features]\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/jacobworsoe/Documents/H23/Maskinl%C3%A6ring/stabekk/notebooks/autogluon_valid.ipynb#X14sZmlsZQ%3D%3D?line=96'>97</a>\u001b[0m y_preds \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel\u001b[39m.\u001b[39;49mpredict(X)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jacobworsoe/Documents/H23/Maskinl%C3%A6ring/stabekk/notebooks/autogluon_valid.ipynb#X14sZmlsZQ%3D%3D?line=97'>98</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mAUTOGLUON MODEL OVERVIEW:\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jacobworsoe/Documents/H23/Maskinl%C3%A6ring/stabekk/notebooks/autogluon_valid.ipynb#X14sZmlsZQ%3D%3D?line=98'>99</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39mleaderboard())\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/autogluon/tabular/predictor/predictor.py:1579\u001b[0m, in \u001b[0;36mTabularPredictor.predict\u001b[0;34m(self, data, model, as_pandas, transform_features, decision_threshold)\u001b[0m\n\u001b[1;32m   1577\u001b[0m \u001b[39mif\u001b[39;00m decision_threshold \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   1578\u001b[0m     decision_threshold \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdecision_threshold\n\u001b[0;32m-> 1579\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_learner\u001b[39m.\u001b[39;49mpredict(X\u001b[39m=\u001b[39;49mdata, model\u001b[39m=\u001b[39;49mmodel, as_pandas\u001b[39m=\u001b[39;49mas_pandas, transform_features\u001b[39m=\u001b[39;49mtransform_features, decision_threshold\u001b[39m=\u001b[39;49mdecision_threshold)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/autogluon/tabular/learner/abstract_learner.py:208\u001b[0m, in \u001b[0;36mAbstractTabularLearner.predict\u001b[0;34m(self, X, model, as_pandas, inverse_transform, transform_features, decision_threshold)\u001b[0m\n\u001b[1;32m    206\u001b[0m     decision_threshold \u001b[39m=\u001b[39m \u001b[39m0.5\u001b[39m\n\u001b[1;32m    207\u001b[0m X_index \u001b[39m=\u001b[39m copy\u001b[39m.\u001b[39mdeepcopy(X\u001b[39m.\u001b[39mindex) \u001b[39mif\u001b[39;00m as_pandas \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m--> 208\u001b[0m y_pred_proba \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpredict_proba(\n\u001b[1;32m    209\u001b[0m     X\u001b[39m=\u001b[39;49mX, model\u001b[39m=\u001b[39;49mmodel, as_pandas\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m, as_multiclass\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m, inverse_transform\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m, transform_features\u001b[39m=\u001b[39;49mtransform_features\n\u001b[1;32m    210\u001b[0m )\n\u001b[1;32m    211\u001b[0m problem_type \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlabel_cleaner\u001b[39m.\u001b[39mproblem_type_transform \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mproblem_type\n\u001b[1;32m    212\u001b[0m y_pred \u001b[39m=\u001b[39m get_pred_from_proba(y_pred_proba\u001b[39m=\u001b[39my_pred_proba, problem_type\u001b[39m=\u001b[39mproblem_type, decision_threshold\u001b[39m=\u001b[39mdecision_threshold)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/autogluon/tabular/learner/abstract_learner.py:188\u001b[0m, in \u001b[0;36mAbstractTabularLearner.predict_proba\u001b[0;34m(self, X, model, as_pandas, as_multiclass, inverse_transform, transform_features)\u001b[0m\n\u001b[1;32m    186\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    187\u001b[0m     \u001b[39mif\u001b[39;00m transform_features:\n\u001b[0;32m--> 188\u001b[0m         X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtransform_features(X)\n\u001b[1;32m    189\u001b[0m     y_pred_proba \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mload_trainer()\u001b[39m.\u001b[39mpredict_proba(X, model\u001b[39m=\u001b[39mmodel)\n\u001b[1;32m    190\u001b[0m y_pred_proba \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_post_process_predict_proba(\n\u001b[1;32m    191\u001b[0m     y_pred_proba\u001b[39m=\u001b[39my_pred_proba, as_pandas\u001b[39m=\u001b[39mas_pandas, index\u001b[39m=\u001b[39mX_index, as_multiclass\u001b[39m=\u001b[39mas_multiclass, inverse_transform\u001b[39m=\u001b[39minverse_transform\n\u001b[1;32m    192\u001b[0m )\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/autogluon/tabular/learner/abstract_learner.py:462\u001b[0m, in \u001b[0;36mAbstractTabularLearner.transform_features\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    460\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mtransform_features\u001b[39m(\u001b[39mself\u001b[39m, X):\n\u001b[1;32m    461\u001b[0m     \u001b[39mfor\u001b[39;00m feature_generator \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfeature_generators:\n\u001b[0;32m--> 462\u001b[0m         X \u001b[39m=\u001b[39m feature_generator\u001b[39m.\u001b[39;49mtransform(X)\n\u001b[1;32m    463\u001b[0m     \u001b[39mreturn\u001b[39;00m X\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/autogluon/features/generators/abstract.py:344\u001b[0m, in \u001b[0;36mAbstractFeatureGenerator.transform\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    342\u001b[0m         \u001b[39mif\u001b[39;00m col \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m X\u001b[39m.\u001b[39mcolumns:\n\u001b[1;32m    343\u001b[0m             missing_cols\u001b[39m.\u001b[39mappend(col)\n\u001b[0;32m--> 344\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(\n\u001b[1;32m    345\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlen\u001b[39m(missing_cols)\u001b[39m}\u001b[39;00m\u001b[39m required columns are missing from the provided dataset to transform using \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    346\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlen\u001b[39m(missing_cols)\u001b[39m}\u001b[39;00m\u001b[39m missing columns: \u001b[39m\u001b[39m{\u001b[39;00mmissing_cols\u001b[39m}\u001b[39;00m\u001b[39m | \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    347\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlen\u001b[39m(\u001b[39mlist\u001b[39m(X\u001b[39m.\u001b[39mcolumns))\u001b[39m}\u001b[39;00m\u001b[39m available columns: \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlist\u001b[39m(X\u001b[39m.\u001b[39mcolumns)\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    348\u001b[0m     )\n\u001b[1;32m    349\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pre_astype_generator:\n\u001b[1;32m    350\u001b[0m     X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pre_astype_generator\u001b[39m.\u001b[39mtransform(X)\n",
      "\u001b[0;31mKeyError\u001b[0m: \"1 required columns are missing from the provided dataset to transform using AutoMLPipelineFeatureGenerator. 1 missing columns: ['ds'] | 51 available columns: ['location', 'weather_data_type', 'absolute_humidity_2m:gm3', 'air_density_2m:kgm3', 'ceiling_height_agl:m', 'clear_sky_energy_1h:J', 'clear_sky_rad:W', 'cloud_base_agl:m', 'dew_or_rime:idx', 'dew_point_2m:K', 'diffuse_rad:W', 'diffuse_rad_1h:J', 'direct_rad:W', 'direct_rad_1h:J', 'effective_cloud_cover:p', 'elevation:m', 'fresh_snow_12h:cm', 'fresh_snow_1h:cm', 'fresh_snow_24h:cm', 'fresh_snow_3h:cm', 'fresh_snow_6h:cm', 'is_day:idx', 'is_in_shadow:idx', 'msl_pressure:hPa', 'precip_5min:mm', 'precip_type_5min:idx', 'pressure_100m:hPa', 'pressure_50m:hPa', 'prob_rime:p', 'rain_water:kgm2', 'relative_humidity_1000hPa:p', 'sfc_pressure:hPa', 'snow_density:kgm3', 'snow_depth:cm', 'snow_drift:idx', 'snow_melt_10min:mm', 'snow_water:kgm2', 'sun_azimuth:d', 'sun_elevation:d', 'super_cooled_liquid_water:kgm2', 't_1000hPa:K', 'total_cloud_cover:p', 'visibility:m', 'wind_speed_10m:ms', 'wind_speed_u_10m:ms', 'wind_speed_v_10m:ms', 'wind_speed_w_1000hPa:ms', 'total_rad_1h:J', 'hour', 'dayofyear', 'month']\""
     ]
    }
   ],
   "source": [
    "ml.utils.make_submittable(\"GluonW_HPO_and_tuning_data_train_test_split.csv\", model=AutoGluonJacob())\n",
    "\n",
    "# df = pd.read_csv(ml.module_dir + '/../submissions/GluonW_HPO_and_tuning_data.csv').merge(pd.read_csv(ml.module_dir + '/../submissions/XGBoostComposite_laptop.csv'), left_index=True, right_index=True)\n",
    "# abs(df.prediction_x - df.prediction_y).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = ml.data.get_training_cleaned()\n",
    "df = df[df.location == 'A']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Now, you can use train_test_split to split the filtered training data\n",
    "train_data, test_data = train_test_split(df, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>location</th>\n",
       "      <th>ds</th>\n",
       "      <th>y</th>\n",
       "      <th>weather_data_type</th>\n",
       "      <th>absolute_humidity_2m:gm3</th>\n",
       "      <th>air_density_2m:kgm3</th>\n",
       "      <th>ceiling_height_agl:m</th>\n",
       "      <th>clear_sky_energy_1h:J</th>\n",
       "      <th>clear_sky_rad:W</th>\n",
       "      <th>cloud_base_agl:m</th>\n",
       "      <th>...</th>\n",
       "      <th>sun_azimuth:d</th>\n",
       "      <th>sun_elevation:d</th>\n",
       "      <th>super_cooled_liquid_water:kgm2</th>\n",
       "      <th>t_1000hPa:K</th>\n",
       "      <th>total_cloud_cover:p</th>\n",
       "      <th>visibility:m</th>\n",
       "      <th>wind_speed_10m:ms</th>\n",
       "      <th>wind_speed_u_10m:ms</th>\n",
       "      <th>wind_speed_v_10m:ms</th>\n",
       "      <th>wind_speed_w_1000hPa:ms</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>26243</th>\n",
       "      <td>A</td>\n",
       "      <td>2022-05-31 09:00:00</td>\n",
       "      <td>5052.30</td>\n",
       "      <td>observed</td>\n",
       "      <td>9.325</td>\n",
       "      <td>1.21300</td>\n",
       "      <td>3777.574951</td>\n",
       "      <td>2.563408e+06</td>\n",
       "      <td>750.824997</td>\n",
       "      <td>1758.649994</td>\n",
       "      <td>...</td>\n",
       "      <td>141.700752</td>\n",
       "      <td>44.165000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>287.050003</td>\n",
       "      <td>72.299999</td>\n",
       "      <td>32652.650391</td>\n",
       "      <td>1.725</td>\n",
       "      <td>-1.500</td>\n",
       "      <td>-0.850</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5784</th>\n",
       "      <td>A</td>\n",
       "      <td>2020-01-29 22:00:00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>observed</td>\n",
       "      <td>4.000</td>\n",
       "      <td>1.25550</td>\n",
       "      <td>1512.200012</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1512.200012</td>\n",
       "      <td>...</td>\n",
       "      <td>338.362495</td>\n",
       "      <td>-43.226500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>276.000000</td>\n",
       "      <td>99.400002</td>\n",
       "      <td>47307.076172</td>\n",
       "      <td>2.750</td>\n",
       "      <td>-2.750</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13540</th>\n",
       "      <td>A</td>\n",
       "      <td>2020-12-18 02:00:00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>observed</td>\n",
       "      <td>4.725</td>\n",
       "      <td>1.27900</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1835.199982</td>\n",
       "      <td>...</td>\n",
       "      <td>60.043750</td>\n",
       "      <td>-39.467251</td>\n",
       "      <td>0.0</td>\n",
       "      <td>277.250000</td>\n",
       "      <td>18.724999</td>\n",
       "      <td>49143.423828</td>\n",
       "      <td>1.750</td>\n",
       "      <td>-1.600</td>\n",
       "      <td>0.600</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28716</th>\n",
       "      <td>A</td>\n",
       "      <td>2022-09-11 10:00:00</td>\n",
       "      <td>1382.48</td>\n",
       "      <td>observed</td>\n",
       "      <td>8.450</td>\n",
       "      <td>1.23650</td>\n",
       "      <td>1017.899979</td>\n",
       "      <td>1.760569e+06</td>\n",
       "      <td>512.499992</td>\n",
       "      <td>369.474998</td>\n",
       "      <td>...</td>\n",
       "      <td>164.511250</td>\n",
       "      <td>30.331500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>282.500000</td>\n",
       "      <td>78.075003</td>\n",
       "      <td>36580.974609</td>\n",
       "      <td>0.500</td>\n",
       "      <td>-0.350</td>\n",
       "      <td>-0.375</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5377</th>\n",
       "      <td>A</td>\n",
       "      <td>2020-01-12 23:00:00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>observed</td>\n",
       "      <td>3.550</td>\n",
       "      <td>1.26425</td>\n",
       "      <td>1862.250031</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1862.250031</td>\n",
       "      <td>...</td>\n",
       "      <td>179.783257</td>\n",
       "      <td>-48.229250</td>\n",
       "      <td>0.0</td>\n",
       "      <td>276.675011</td>\n",
       "      <td>97.875000</td>\n",
       "      <td>54268.250000</td>\n",
       "      <td>3.400</td>\n",
       "      <td>1.000</td>\n",
       "      <td>3.250</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18285</th>\n",
       "      <td>A</td>\n",
       "      <td>2021-07-03 19:00:00</td>\n",
       "      <td>338.80</td>\n",
       "      <td>observed</td>\n",
       "      <td>11.475</td>\n",
       "      <td>1.20250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.869624e+05</td>\n",
       "      <td>87.324999</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>306.243996</td>\n",
       "      <td>8.297000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>290.300003</td>\n",
       "      <td>3.550000</td>\n",
       "      <td>47196.700195</td>\n",
       "      <td>4.325</td>\n",
       "      <td>4.300</td>\n",
       "      <td>-0.400</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18841</th>\n",
       "      <td>A</td>\n",
       "      <td>2021-07-26 23:00:00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>observed</td>\n",
       "      <td>9.750</td>\n",
       "      <td>1.20000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>179.517504</td>\n",
       "      <td>-7.056750</td>\n",
       "      <td>0.0</td>\n",
       "      <td>295.550003</td>\n",
       "      <td>0.175000</td>\n",
       "      <td>53892.149414</td>\n",
       "      <td>2.750</td>\n",
       "      <td>-2.100</td>\n",
       "      <td>1.800</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25198</th>\n",
       "      <td>A</td>\n",
       "      <td>2022-04-17 20:00:00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>observed</td>\n",
       "      <td>5.975</td>\n",
       "      <td>1.26950</td>\n",
       "      <td>7216.400024</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5583.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>316.535500</td>\n",
       "      <td>-8.953500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>284.150002</td>\n",
       "      <td>87.400002</td>\n",
       "      <td>32406.649902</td>\n",
       "      <td>0.600</td>\n",
       "      <td>-0.025</td>\n",
       "      <td>0.600</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22465</th>\n",
       "      <td>A</td>\n",
       "      <td>2021-12-24 23:00:00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>observed</td>\n",
       "      <td>3.425</td>\n",
       "      <td>1.29450</td>\n",
       "      <td>3423.950012</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>350.750000</td>\n",
       "      <td>...</td>\n",
       "      <td>181.709994</td>\n",
       "      <td>-49.875501</td>\n",
       "      <td>0.0</td>\n",
       "      <td>270.799995</td>\n",
       "      <td>92.000000</td>\n",
       "      <td>25039.450195</td>\n",
       "      <td>4.450</td>\n",
       "      <td>4.275</td>\n",
       "      <td>1.250</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>934</th>\n",
       "      <td>A</td>\n",
       "      <td>2019-07-11 20:00:00</td>\n",
       "      <td>82.50</td>\n",
       "      <td>observed</td>\n",
       "      <td>9.150</td>\n",
       "      <td>1.22700</td>\n",
       "      <td>911.100006</td>\n",
       "      <td>1.560772e+05</td>\n",
       "      <td>18.850001</td>\n",
       "      <td>911.100006</td>\n",
       "      <td>...</td>\n",
       "      <td>319.189751</td>\n",
       "      <td>2.569000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>285.025002</td>\n",
       "      <td>3.450000</td>\n",
       "      <td>42243.674805</td>\n",
       "      <td>3.350</td>\n",
       "      <td>3.325</td>\n",
       "      <td>0.400</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>17043 rows × 49 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      location                  ds        y weather_data_type  \\\n",
       "26243        A 2022-05-31 09:00:00  5052.30          observed   \n",
       "5784         A 2020-01-29 22:00:00     0.00          observed   \n",
       "13540        A 2020-12-18 02:00:00     0.00          observed   \n",
       "28716        A 2022-09-11 10:00:00  1382.48          observed   \n",
       "5377         A 2020-01-12 23:00:00     0.00          observed   \n",
       "...        ...                 ...      ...               ...   \n",
       "18285        A 2021-07-03 19:00:00   338.80          observed   \n",
       "18841        A 2021-07-26 23:00:00     0.00          observed   \n",
       "25198        A 2022-04-17 20:00:00     0.00          observed   \n",
       "22465        A 2021-12-24 23:00:00     0.00          observed   \n",
       "934          A 2019-07-11 20:00:00    82.50          observed   \n",
       "\n",
       "       absolute_humidity_2m:gm3  air_density_2m:kgm3  ceiling_height_agl:m  \\\n",
       "26243                     9.325              1.21300           3777.574951   \n",
       "5784                      4.000              1.25550           1512.200012   \n",
       "13540                     4.725              1.27900                   NaN   \n",
       "28716                     8.450              1.23650           1017.899979   \n",
       "5377                      3.550              1.26425           1862.250031   \n",
       "...                         ...                  ...                   ...   \n",
       "18285                    11.475              1.20250                   NaN   \n",
       "18841                     9.750              1.20000                   NaN   \n",
       "25198                     5.975              1.26950           7216.400024   \n",
       "22465                     3.425              1.29450           3423.950012   \n",
       "934                       9.150              1.22700            911.100006   \n",
       "\n",
       "       clear_sky_energy_1h:J  clear_sky_rad:W  cloud_base_agl:m  ...  \\\n",
       "26243           2.563408e+06       750.824997       1758.649994  ...   \n",
       "5784            0.000000e+00         0.000000       1512.200012  ...   \n",
       "13540           0.000000e+00         0.000000       1835.199982  ...   \n",
       "28716           1.760569e+06       512.499992        369.474998  ...   \n",
       "5377            0.000000e+00         0.000000       1862.250031  ...   \n",
       "...                      ...              ...               ...  ...   \n",
       "18285           4.869624e+05        87.324999               NaN  ...   \n",
       "18841           0.000000e+00         0.000000               NaN  ...   \n",
       "25198           0.000000e+00         0.000000       5583.500000  ...   \n",
       "22465           0.000000e+00         0.000000        350.750000  ...   \n",
       "934             1.560772e+05        18.850001        911.100006  ...   \n",
       "\n",
       "       sun_azimuth:d  sun_elevation:d  super_cooled_liquid_water:kgm2  \\\n",
       "26243     141.700752        44.165000                             0.0   \n",
       "5784      338.362495       -43.226500                             0.0   \n",
       "13540      60.043750       -39.467251                             0.0   \n",
       "28716     164.511250        30.331500                             0.0   \n",
       "5377      179.783257       -48.229250                             0.0   \n",
       "...              ...              ...                             ...   \n",
       "18285     306.243996         8.297000                             0.0   \n",
       "18841     179.517504        -7.056750                             0.0   \n",
       "25198     316.535500        -8.953500                             0.0   \n",
       "22465     181.709994       -49.875501                             0.0   \n",
       "934       319.189751         2.569000                             0.0   \n",
       "\n",
       "       t_1000hPa:K  total_cloud_cover:p  visibility:m  wind_speed_10m:ms  \\\n",
       "26243   287.050003            72.299999  32652.650391              1.725   \n",
       "5784    276.000000            99.400002  47307.076172              2.750   \n",
       "13540   277.250000            18.724999  49143.423828              1.750   \n",
       "28716   282.500000            78.075003  36580.974609              0.500   \n",
       "5377    276.675011            97.875000  54268.250000              3.400   \n",
       "...            ...                  ...           ...                ...   \n",
       "18285   290.300003             3.550000  47196.700195              4.325   \n",
       "18841   295.550003             0.175000  53892.149414              2.750   \n",
       "25198   284.150002            87.400002  32406.649902              0.600   \n",
       "22465   270.799995            92.000000  25039.450195              4.450   \n",
       "934     285.025002             3.450000  42243.674805              3.350   \n",
       "\n",
       "       wind_speed_u_10m:ms  wind_speed_v_10m:ms  wind_speed_w_1000hPa:ms  \n",
       "26243               -1.500               -0.850                      0.0  \n",
       "5784                -2.750                0.100                      0.0  \n",
       "13540               -1.600                0.600                      0.0  \n",
       "28716               -0.350               -0.375                      0.0  \n",
       "5377                 1.000                3.250                      0.0  \n",
       "...                    ...                  ...                      ...  \n",
       "18285                4.300               -0.400                      0.0  \n",
       "18841               -2.100                1.800                      0.0  \n",
       "25198               -0.025                0.600                      0.0  \n",
       "22465                4.275                1.250                      0.0  \n",
       "934                  3.325                0.400                      0.0  \n",
       "\n",
       "[17043 rows x 49 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
